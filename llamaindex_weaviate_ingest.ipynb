{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core.node_parser import SimpleNodeParser\n",
    "import os\n",
    "import weaviate\n",
    "from weaviate.classes.init import Auth\n",
    "\n",
    "wcd_url = os.environ[\"WCD_URL\"]\n",
    "wcd_api_key = os.environ[\"WCD_API_KEY\"]\n",
    "\n",
    "client = weaviate.connect_to_weaviate_cloud(\n",
    "    cluster_url=wcd_url,                                    \n",
    "    auth_credentials=Auth.api_key(wcd_api_key),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.007724063005298376, 0.039427097886800766, -0.017061689868569374, -0.02000819891691208, 0.024540210142731667]\n",
      "\n",
      "\n",
      "3072\n"
     ]
    }
   ],
   "source": [
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core import Settings\n",
    "\n",
    "embed_model = OpenAIEmbedding(model=\"text-embedding-3-large\")\n",
    "\n",
    "Settings.embed_model = embed_model\n",
    "\n",
    "embeddings = embed_model.get_text_embedding(\n",
    "    \"OpenAI new Embeddings models is great.\"\n",
    ")\n",
    "\n",
    "print(embeddings[:5])\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(len(embeddings))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ingest the docs in the data folder\n",
    "\n",
    "docs = SimpleDirectoryReader('./data').load_data()\n",
    "\n",
    "parser = SimpleNodeParser()\n",
    "nodes = parser.get_nodes_from_documents(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, StorageContext\n",
    "from llama_index.vector_stores.weaviate import WeaviateVectorStore\n",
    "\n",
    "\n",
    "# construct vector store\n",
    "vector_store = WeaviateVectorStore(weaviate_client = client, index_name=\"James\")\n",
    "\n",
    "# setting up the storage for the embeddings\n",
    "storage_context = StorageContext.from_defaults(vector_store = vector_store)\n",
    "\n",
    "# set up the index\n",
    "index = VectorStoreIndex(nodes, storage_context = storage_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To maximize your charge, it is recommended to avoid letting the Battery capacity drop too low, refer to the vehicle touchscreen or mobile app for charging limits, ensure the Wall Connectors are configured for a 48A charge current, confirm the charge port light blinks green when charging, and follow proper procedures when unlatching the charge cable.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"How can I maximize my charge?\")\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
